[
  {
    "index": 0,
    "level": 1,
    "start_page": 1,
    "end_page": 52,
    "title": "L01 Introduction to Neural Networks",
    "content": "Neural Networks Charith Chitraranjan Outline â€¢ Brief look at biological neurons and their networks â€¢ Basic artificial neurons and neural networks â€¢ Why study neural networks â€¢ A simple pattern recognition example â€¢ Perceptron and Learning â€¢ Performance of neural networks in popular machine learning problems Neurons and Their Networks â€¢ What is a neural network? - A network of interconnected nerve cells called neurons. â€¢ The nervous systems (especially the brains) of animals are composed of neural networks. â€¢ Adult human brain has about a trillion neurons Biological Neuron â€¢ What is a neuron? - The basic unit of a nervous system. It's a type of cell. â€¢ What does a neuron do? - Receive input from other neurons at the synapses and if required conditions are satisfied, produce an output (a spike train) through the axon. Biological Neuron A neuron receives electrical signals through the axons terminals of other neurons. These signals have to cross a gap (called the synaptic cleft) at the synapses before entering the dendrites that carry the signal into the cell body (soma). What portion of the signal passes onto the dendrites will depend on the strength of the particular synapse. In modeling neurons, the input signal at each synapse is multiplied by its strength (weight ), w. Therefore, the resultant signal received by the cell body is the weighted sum of the pre-synaptic signals. If the signal present at the cell body is large enough to cause sufficient depolarization of the neural membrane, the neuron will fire and a voltage spike called an action potential will be transmitted through the output axon. There are two types of synapses; excitatory and inhibitory. Excitatory synapses cause membrane depolarization and contribute to fire the neuron. Such synapses are modeled with positive weights Inhibitory synapses cause membrane hyperpolarization and inhibit the firing of the neuron. Such synapses are modeled with negative weights Biological Neuron A neuron receives electrical signals through the axons terminals of other neurons. These signals have to cross a gap (called the synaptic cleft) at the synapses before entering the dendrites that carry the signal into the cell body (soma). What portion of the signal passes onto the dendrites will depend on the strength of the particular synapse. In modeling neurons, the input signal at each synapse is multiplied by its strength (weight ), w. Therefore, the resultant signal received by the cell body is the weighted sum of the pre-synaptic signals. If the signal present at the cell body is large enough to cause sufficient depolarization of the neural membrane, the neuron will fire and a voltage spike called an action potential will be transmitted through the output axon. There are two types of synapses; excitatory and inhibitory. Excitatory synapses cause membrane depolarization and contribute to fire the neuron. Such synapses are modeled with positive weights Inhibitory synapses cause membrane hyperpolarization and inhibit the firing of the neuron. Such synapses are modeled with negative weights Models of Artificial Neurons â€¢ Binary threshold Neurons â€¢ Rectified linear Neurons (aka Linear threshold neurons) â€¢ Sigmoid Neurons Binary Threshold Neuron (McCulloch-Pitts Model) In a network, a neuron typically receives input from many other neurons and its output may be fed into many other neurons as well. A very simple model of a neuron. ğ‘‚ğ‘¢ğ‘¡ğ‘ğ‘¢ğ‘¡= àµ ğ‘–ğ‘“ğ‘§â‰¥ ğ‘œğ‘¡â„ğ‘’ğ‘Ÿğ‘¤ğ‘–ğ‘ ğ‘’ ğ‘§= à· ğ‘¥ğ‘–ğ‘¤ğ‘– Simple Artificial Neuron: Rectified Linear Neuron otherwise Output f(z) Simple Artificial Neuron: Sigmoid Neuron These use the sigmoid (logistic) function to produce the output. It is a continuous output function with nice derivatives that make learning easier. output 0.5 A Simple Artificial Neural Network Source: http://mechanicalforex.com/2011/06/neural-networks-in-trading-how- to-design-a-network-for-financial-forecasting-in-eight-simple-steps.html A simple feed-forward neural network with one hidden layer Why study/use neural networks â€¢ To help understand how the brain works - Mammalian brains are complex and contain trillions of neurons. Thus difficult to understand. â€¢ Simplified artificial neural networks can be used to solve practical machine learning problems. E.g., - Visual object recognition - Recognition of hand-written digits - Speech recognition - And other problems in the general areas of classification, prediction and clustering. A simple Pattern Recognition Example â€¢ Assume a 3x3 dot-matrix display as shown below that can display several patterns including several English characters such as, â€¢ Suppose out of everything it can display, we want to recognize the characters T and L. â€¢ Suppose we mark each cell as xi for i=1, 2,...,9 as follows with xi = 1 if the cell is shaded and 0 otherwise. â€¢ We can use the following artificial neural network to solve this problem. Weights on the edges are the multiplicative synaptic weights Number within each neuron is its spiking threshold. In this case, all are 1 and they are binary threshold neurons. 0.2 0.2 0.2 0.2 0.2 Outputs 1 for input T Outputs 1 for input L 0.25 0.25 0.25 0.25 Perceptron Output Perceptron Output and where Perceptron Output and where Perceptron Learning â€¢ In supervised learning, we want a perceptron to learn to separate data into two classes. â€¢ Let P ={x(1),..., x(L)} and N ={x(1),..., x(M)} be two classes (sets) of data that we want the perceptron to learn to separate. - Also assume that the data is linearly separable. E.g., 2D and 3D data shown below. Perceptron Learning â€¢ We want to find a set of weights that satisfy the following. â€¢ When the classes P and N are linearly separable, the perceptron leaning algorithm can be used to learn weights that satisfy the above. For ğ‘›-dim ğ‘’ğ‘›ğ‘ ğ‘–ğ‘œğ‘›ğ‘ğ‘™ data, âˆ€ğ‘¥(ğ‘˜) âˆˆğ‘ƒ, à· ğ‘–=0 ğ‘¤ğ‘–ğ‘¥ğ‘– (ğ‘˜) â‰¥0 ğ‘ğ‘›ğ‘‘ âˆ€ğ‘¥(ğ‘˜) âˆˆğ‘, à· ğ‘–=0 ğ‘¤ğ‘–ğ‘¥ğ‘– (ğ‘˜) < 0 Perceptron Learning Algorithm In this algorithm, - if a data point in P is misclassified, the weight vector is rotated towards that data point. - if a data point in N is misclassified, the weight vector is rotated away from that data point. If the data is linearly separable, the algorithm will find a weight vector that produces zero error in a finite number of iterations. chosen randomly each For randomly Initializw and and w=[w Perceptron Learning Algorithm 0 + w ï² Suppose ğ’™(k) is in the positive class but is misclassified as negative (under the separating line) Perceptron Learning Algorithm 0 + w ï² Suppose ğ’™(k) is in the negative class but is misclassified as positive (above the separating line) The pocket Algorithm â€¢ If the data is not linearly separable, the perceptron leaning algorithm does not converge to a solution. â€¢ In such cases, we want to find a weight vector ws that minimizes the number of misclassified data points. â€¢ A variant of the perceptron learning algorithm, known as the pocket algorithm produces an approximation to ws. - It uses the perceptron learning algorithm to update the weight vector - At any given time, it attempts to keep the best* weight vector found so far and updates it if a better one is found. * One that produces the least number of misclassified data points in the last run. The pocket Algorithm Reference: Raul Rojas, Neural Networks: A Systematic Introduction, Springer-Verlag, 1996. Performance of Artificial Neural Networks on Machine Learning Problems â€¢ ImageNet: Object Recognition - 1000 different object classes in 1.3 million high- resolution images from the web. Task is to correctly identify these objects. - Best system in the 2010 competition got 47% error for its first choice and 25% error for its top 5 choices. - A very deep neural net (Krizhevsky et. al. 2012) got less that 40% error for its first choice and less than 20% for its top 5 choices Source: Based on the Slides Prepared By: Geoffrey Hinton, Nitish Srivastava, Kevin Swersky. https://class.coursera.org/neuralnets-2012-001/class/index Some examples from an earlier version of the net Source: Based on the Slides Prepared By: Geoffrey Hinton, Nitish Srivastava, Kevin Swersky. https://class.coursera.org/neuralnets-2012-001/class/index Performance of Artificial Neural Networks on Machine Learning Problems Speech Recognition â€¢ A speech recognition system has several stages: - Pre-processing: Convert the sound wave into a vector of acoustic coefficients. Extract a new vector about every 10 milli- seconds. - The acoustic model: Use a few adjacent vectors of acoustic coefficients to place bets on which part of which phoneme is being spoken. - Decoding: Find the sequence of bets that does the best job of fitting the acoustic data and also fitting a model of the kinds of things people typically say. â€¢ Deep neural networks pioneered by George Dahl and Abdel-rahman Mohamed are now replacing the previous machine learning method for the acoustic model. Source: Based on the Slides Prepared By: Geoffrey Hinton, Nitish Srivastava, Kevin Swersky. https://class.coursera.org/neuralnets-2012-001/class/index Word error rates from MSR, IBM,. & Google (Hinton et. al. IEEE Signal Processing Magazine, Nov 2012) The task Hours of training data Deep neural network Gaussian Mixture Model GMM with more data Switchboard (Microsoft Research) 18.5% 27.4% 18.6% (2000 hrs) English broadcast news (IBM) 17.5% 18.8% Google voice search (android 4.1) 5,870 12.3% (and falling) 16.0% (>>5,870 hrs) References â€¢ Raul Rojas, Neural Networks: A Systematic Introduction, Springer-Verlag, 1996. â€¢ Ian Goodfellow, Yoshua Bengio, Aaron Courville: Deep Learning, MIT Press, 2016. Back Propagation for Supervised Learning with Neural Networks Charith Chitraranjan Outline â€¢ A simple multilayer feed forward neural network. â€¢ An objective for learning the weights â€¢ Gradient decent â€¢ Back propagation: An example â€¢ Modular approach to back propagation A Feed Forward Neural Network We need to find appropriate values for the weights w1, ..., w14 so that the outputs z1 and z2 behave desirably. Each neuron computes h(ï“wx). I.e., h(weighted sum of its inputs). h is some transfer function. E.g., the sigmoid function w1 x w10 w14 Adjusting the Weights Consider the same network in the previous slide. Assume we have a set of labeled training examples (Xi,di 1,di 2) with i=1,..., N. - Xi is the input vector and di 1, di 2 are the actual(desired) outputs for the ith example. Table below shows part of the Iris data as an example ( only 3 out of the 4 features in the original data set). Data point Input (X) Desired output Sepal Length (x1) Sepal Width (x2) Petal Length (x3) Setosa (d1) Virginica(d2) 4.9 1.4 4.6 3.1 1.5 4.7 3.2 1.3 5.4 3.9 1.7 4.6 3.4 1.4 Adjusting the Weights â€¢ Consider the same example as before. â€¢ We can compute a prediction error (E) that depends on the mismatch between the desired outputs di 1,di 2 and predicted outputs 1,zi - E.g., Squared difference â€¢ We can adjust the weights such that E reaches its minimum. Adjusting the Weights â€¢ Eventually, error (E) is a function of the weights and the inputs. - Why not just express E, in terms of w's and x's and minimize it ? â€¢ For a network of decent size and non-linear transfer functions, expressing E analytically in terms of weights and minimizing it becomes tedious and almost impossible. â€¢ Neural networks with just input and output layers (no hidden layers) are very limited in what they can do and they need carefully crafted features, which are tedious to get. â€¢ Neural networks with many hidden layers (deep neural nets), can learn features without much human intervention. â€¢ So, we use numerical methods to adjust the weights. - Gradient decent is a popular choice Gradient Decent E = 1 w E = â€¢ Let the current values be w1=a and w2=b. â€¢ We want to reduce the error. So, we need to change w1 and w2 along some direction that has a negative gradient (down hill). Gradient Decent Gradient Decent E = 1 w E = â€¢ Let the current values be w1=a and w2=b. â€¢ We want to reduce the error. So, we need to change w1 and w2 along some direction that has a negative gradient (down hill). â€¢ is the direction of the maximum gradient. So, we move in the opposite direction specified by . Gradient Decent E = 1 w E = â€¢ Let the current values be w1=a and w2=b. â€¢ We want to reduce the error. So, we need to change w1 and w2 along some direction that has a negative gradient (down hill). â€¢ is the direction of the maximum gradient. So, we move in the opposite direction specified by . Gradient Decent: Update step â€¢ Let f(w1,...wj ,...wN) be a function of N variables. â€¢ Then, in the kth iteration, each variable wj will be updated as follows ,..., ,..., point at the evaluated w.r.t derivative partial the and rate learning the where Gradient Decent: Update step â€¢ Let f(w1,...wj ,...wN) be a function of N variables. â€¢ Then, in the kth iteration, each variable wj will be updated as follows ,..., ,..., point at the evaluated w.r.t derivative partial the and rate learning the where Gradient Decent â€¢ To perform gradient decent, we need the partial derivatives of the error w.r.t. weights. I.e., â€¢ We find these partial derivatives using the back propagation algorithm. - Propagate the error from the output layer back to the input layer through the hidden layers. Chain Rule of Differentiation Back propagation relies on the chain rule. â€¢ Let z be a function of the two variables u and v - I.e., â€¢ Let u and v each be a function of the two variables x and y. - I.e., â€¢ Then from the chain rule, the partial derivatives of z w.r.t x and y are, z = Back Propagation Error fn â€¢ Suppose we have a labeled training dataset containing N entries of the form with i=1,..., N, where x1 and x2 are the input attributes and d is the actual/desired output. â€¢ In order to do a gradient decent to find the weights such that the predicted outputs z2's are as close as possible to the actual outputs d's, we need the following derivatives. Neuron 1 Neuron 2 Back Propagation )1( Back Propagation (i) (i) (i) and output output (1) and Substitute is, neuron sigmoid derivative the general i.e., threshold zero and activation sigmoid have neurons the Assume Back Propagation Similarly Back Propagation: A Modular Approach lz1 lz2 l th layer We can assume that the last module computes the error. Then, ZL+1=E. Therefore message forward the Is the backward message Same Example in Modular Form 4 = ğ‘“3(ğ‘§1 3) = ğ¸= 1 2 ğ‘§1 3 -ğ‘‘2 Module 1: f1 4 = ğ¸ Module 2: f2 Module 3 (error) ğ‘™= ğœ•ğ¸ ğœ•ğ‘ğ‘— 4 = ğœ•ğ¸ ğœ•ğ‘1 4 = ğœ•ğ¸ ğœ•ğ¸= 1 ğ‘™= à· ğ‘™+1 ğœ•ğ‘ğ‘˜ ğœ•ğ‘ğ‘— 3 = ğ›¿1 4 ğœ•ğ‘1 ğœ•ğ‘1 3 = ğ‘§1 3 -ğ‘‘ 2 = ğ›¿1 3 ğœ•ğ‘1 ğœ•ğ‘1 2 = ğ‘§1 3 -ğ‘‘ğ‘1 3(1 -ğ‘1 3)ğ‘¤1 1 = ğ›¿1 2 ğœ•ğ‘1 ğœ•ğ‘1 = ğ‘§1 3 -ğ‘‘ğ‘1 3(1 -ğ‘1 3)ğ‘¤1 2ğ‘1 2 1 -ğ‘1 2 ğ‘¤1 1 = ğ›¿1 2 ğœ•ğ‘1 ğœ•ğ‘2 = ğ‘§1 3 -ğ‘‘ğ‘1 3(1 -ğ‘1 3)ğ‘¤1 2ğ‘1 2(1 -ğ‘1 2)ğ‘¤2 Same Example in Modular Form... ğœ•ğ‘¤12 = ğ›¿1 3 ğœ•ğ‘13 ğœ•ğ‘¤12 = ğ‘§1 3 -ğ‘‘ ğ‘1 3(1 -ğ‘1 3) ğ‘§1 Module 1: f1 4 = ğ¸ Module 2: f2 Module 3 (error) ğœ•ğ‘¤ğ‘š ğ‘™= à· ğ‘™+1 ğœ•ğ‘ğ‘˜ ğ‘™+1 ğœ•ğ‘¤ğ‘š ğœ•ğ‘¤11 = ğ›¿1 2 ğœ•ğ‘12 ğœ•ğ‘¤11= ğ‘§1 3 -ğ‘‘ğ‘1 3(1 -ğ‘1 3)ğ‘¤1 2 ğ‘1 2 1 -ğ‘1 2 ğ‘§1 ğœ•ğ‘¤21 = ğ›¿1 2 ğœ•ğ‘12 ğœ•ğ‘¤21= ğ‘§1 3 -ğ‘‘ğ‘1 3(1 -ğ‘1 3)ğ‘¤1 2 ğ‘1 2 1 -ğ‘1 2 ğ‘§2 ğ¸= 1 2 à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğœ•ğ‘¤1 = à· ğ‘–=1 ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘¤1 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘¤1 ğœ•ğ‘¤1 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘¤1 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘§1 (ğ‘–) ğœ•ğ‘§1 (ğ‘–) ğœ•ğ‘¤1 ğœ•ğ‘¤1 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğœ•ğ‘§2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘¦2 (ğ‘–) ğœ•ğ‘§1 (ğ‘–) ğœ•ğ‘§1 (ğ‘–) ğœ•ğ‘¦1 (ğ‘–) ğœ•ğ‘¦1 (ğ‘–) ğœ•ğ‘¤1 ğœ•ğ‘¤1 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğ‘§2 (ğ‘–)(1 -ğ‘§2 (ğ‘–))ğ‘¤3ğ‘§1 (ğ‘–)(1 -ğ‘§1 (ğ‘–))ğ‘¥1 (ğ‘–) ğ‘†ğ‘–ğ‘šğ‘–ğ‘™ğ‘ğ‘Ÿğ‘™ğ‘¦, ğœ•ğ¸ ğœ•ğ‘¤2 = à· ğ‘–=1 (ğ‘–) -ğ‘‘(ğ‘–) ğ‘§2 (ğ‘–)(1 -ğ‘§2 (ğ‘–))ğ‘¤3ğ‘§1 (ğ‘–)(1 -ğ‘§1 (ğ‘–))ğ‘¥2 (ğ‘–) Useful Links â€¢ https://www.youtube.com/watch?v=q0pm3Br IUFo â€¢ https://www.youtube.com/watch?v=- YRB0eFxeQA&list=PLE6Wd9FR-- EfW8dtjAuPoTuPcqmOV53Fu&index=10"
  },
  {
    "index": 1,
    "level": 1,
    "start_page": 53,
    "end_page": 70,
    "title": "L02 Loss Functions Regularization",
    "content": "Loss Functions and Regularization Charith Chitraranjan Outline â€¢ Error or loss functions for classification problems â€¢ Regularization Error Functions: Binary Classification â€¢ Two classes (0,1) in the data. â€¢ Let tn be the target value (actual class) for the nth data sample. - tn is either 1 or 0 Let the prediction of the network for the nth data sample, denoted yn, represent the probability of class label 1 given the inputs of sample n, i.e, our objective is to make yn = P(tn =1|inputsn) Inputs Output (y) Error Functions: Binary Classification â€¢ If the output neuron has a sigmoid activation function, â–ª . â–ªit produces output values between 0 and 1. So, qualifies to be a probability â€¢ We train the model such that yn gets as close as possible to the desired probability P(tn =1|inputsn) â€¢ We need to specify a suitable error/loss function and adjust the weights of the network to minimize that function. exp( Binary Classification: Squared Error (SE sample error Squared â€¢ This is simple, but doesn't work very well in practice â€¢ It is susceptible to outliers Red and blue represent two classes of points Binary Classification: Cross Entropy with Logistic Loss Cross Entropy between two probability distributions p and q are defined as below - H(p,q) is low when p and q are similar and is high when p and q are dissimilar. E.g., let X be a random variable representing the outcome of a coin toss. So, the possible values are X=H and X=T. Suppose there are two coins. One is fair and the other is biased, and let p and q be their probability distribution functions respectively with the following values. If both coins were fair, log[ )3.0 log 5.0 7.0 log 5.0 log( log( 3.0 ,7.0 5.0 then 5.0 log 5.0 5.0 log 5.0 5.0 then Binary Classification: Cross Entropy with Logistic Loss â€¢ Cross Entropy between two probability distributions p and q are defined as below - H(p,q) is low when p and q are similar and is high when p and q are dissimilar. â€¢ In our case we'll let p be the distribution of the actual class label (t) and q be that of the predicted class label (y) log[ log( log( (CEL sample for logistic entropy wi cross Binary Classification: Cross Entropy with Logistic Loss Line of separation with cross-entropy logistic loss Line of separation with squared error Multi-Class Classification: Cross Entropy with Logistic Loss If the classes are independent, Inputs log( log( samples data independen for CEL log( log( (CEL sample for activation logistic entropy wi cross Multi-Class Classification: Cross Entropy with Softmax â€¢ If a given sample should belong to one and only one class, then we would have to add a softmax layer Softmax Layer exp( exp( Multi-Class Classification: Cross Entropy with Softmax log( samples data independen for activation Softmax entropy wi Cross Regularization â€¢ Any strategy that makes a model perform better not just on training data but also on previously unseen test data. - Reducing the generalization error instead of training error. - Avoid overfitting (and underfitting too) Image source: www.geeksforgeeks.org Appropriate fit ğœƒ0 + ğœƒ1ğ‘¥+ ğœƒ2ğ‘¥2 + ğœƒ3ğ‘¥3 +ğœƒ4 ğ‘¥4 Regularization - Fitting for Classification Image source: www.geeksforgeeks.org Regularization â€¢ Let J be the error to be minimized and is a function of parameters (weights) w. - without reqularization we just try to minimize J(w) - with regularization, we try to minimize J(w)+Î»Î©(w) where Î» is a constant and Î©(w) is a parameter norm penalty. E.g. Lp norm. Regularization - Exampls of Norm Penanlties â€¢ L2 norm Minimize J(w)+Î»Î£(wi)2 E.g., for linear regression Regularization gives numerical stability to linear regression when the data is poorly conditioned (many dimension and few data points) contours contours Î»Î£(wi)2 is the penalty here Regularization - Exampls of Norm Penanlties â€¢ L1 norm Minimize J(w)+Î»Î£|wi| E.g., for linear regression contours L2 Vs L1 Regularization â€¢ Both L2 and L1 regularization both try to make the model simpler by bringing some parameters (not so important ones) closer to â€¢ L1 regularization brings parameters to zero more aggressively making the model sparser by completely eliminating (zero) unimportant model parameters. Some useful Video Lectures â€¢ https://youtu.be/hrIad1RVFV0?list=PLE6Wd9F R--EdyJ5lbFl8UuGjecvVw66F6&t=2116 â€¢ https://www.youtube.com/watch?v=PKXpaLUi gA8 â€¢ https://www.youtube.com/watch?v=KvtGD37 Rm5I&list=PLLssT5z_DsK- h9vYZkQkYNWcItqhlRJLN&index=40"
  },
  {
    "index": 2,
    "level": 1,
    "start_page": 71,
    "end_page": 93,
    "title": "L03 Convolutional Neural Networks",
    "content": "Convolutional Neural Networks Charith Chitraranjan Outline â€¢ Convolutional Neural Networks for Image Data - Convolutional layer - Pooling layer â€¢ Why use convolutional nets â€¢ Derivatives for back propagation Convolutional Layer For an Image â€¢ Basic Idea: You take an image and slide a filter over it. - The filter computes a weighted sum of the pixels it covers. â€¢ The feature map is the output of the filter as applied to the image. - It has the same number of pixels as the image. - The image is usually padded with zeros to allow the filter slide over the edges of the image Feature Map Image Application of a Filter w11 w12 w21 w22 x11 x1n xij xn1 xmn Filter Image Application of a Filter w11 w12 w21 w22 x11 x1n xij xn1 xmn Feature map Image image, in the cell placed filter the ,j+v- i+u- (i,j) z11 z1n zij zn1 zmn Application of a Filter For the image, light grey = 0 and dark grey = 1 For the filter a red dot means a weight of 1. No dot means a weight of 0. For the feature map, higher the value, the darker the cell is. Feature map in values and colors Image Filter Application of a Filter â€¢ An image typically has multiple channels, e.g., RGB. Therefore, it's not a 2D matrix but a 3D volume. If the image has D channels the depth of the volume is D. â€¢ Hence, the filter too is a 3D volume with the same depth (D) as the image. image, the cell it' filter whe the Output ,j+v- i+u- uvk (i,j) Application of a Filter â€¢ Typically, multiple individual filters are applied to an image. - Results in a separate feature map for each filter. - If Nf is the number of filters used, there'll be Nf feature maps generated. Application of a Filter filter weights the are and map feature cell value the that Note by, given image the cell it' when filter Output (i,j) (i,j) uvkp ijp ,j+v- i+u- uvkp ijp ijp Feature map p Application of a Filter filter weights the are and map feature cell value the that Note by, given image the cell it' when filter Output (i,j) (i,j) uvkp ijp ,j+v- i+u- uvkp ijp ijp Feature map p Pooling Layer â€¢ After a convolutional layer (filtering), the feature maps are sub-sampled. x11 x1n xij xn1 xmn z11 zqr Pooling Layer x11p x1np xijp xn1p xmnp z11p zqrp area this Let max map feature For ijp i,j qrp â€¢ Max operation is commonly used in the pooling layer: Max pooler Convolutional Neural Network â€¢ A convolutional NN is a collection of alternating convolutional and pooling layers. â€¢ Typically at the end, a fully connected feed forward NN with a hidden layer is present. CNN Features CNN Features Convolutional nets Vs. fully connected nets Consider two layers with nï‚´m neurons each. â€¢ A fully connected network would have (nï‚´m)2 number of weights to learn â€¢ A convolutional layer with a filter of size sï‚´r would involve only sï‚´r weights. - Typically sï‚´r <<< nï‚´m - Remember, it's the same filter that is slid over the image. â€¢ Convolutional layers allow us to build deep networks (many layers) for object recognition. - These do better than other methods. (They won the image net competition) Back Propagation: A Modular Approach lz1 lz2 Then Let l th layer We can assume that the last module computes the error. Then, ZL+1=E. Therefore message forward the Convolutional Layer ijk qrp Derivatives for Convolutional Layer l â€¢ From the equations in the previous slide ,r+v- q+u- qrp uvkp qrp qrp uvkp ijk ijk ,r+v- q+u- uvkp qrp Then Let (same equation as in slide 10) Derivatives for Convolutional Layer l otherwise qrp ijk uvkp qrp ijk qrp qrp ijk qrp qrp ijk ijk ijk ,r+v- q+u- uvkp qrp Therefore r+v- when and q+u- when r+v- and q+u- where and with Derivatives for Max Pooling Layer l otherwise argmax if ,1 max{ and where and with xyk ijk ijk qrp ijk qrp qrp ijk qrp qrp ijk ijp ijp xyp qrp Prominent CNN architectures â€¢ Resnet (Kaiming He et al., 2015) - 152 layers, Winner Imagenet 2015. â€¢ GoogleNet (Szegedy et al., 2015) - 22 Layers Winner Imagenet 2014. â€¢ VGG (Simonyan et. al., 2014) - 19 Layers, 2nd place, Imagenet 2014. Reference â€¢ Machine learning lecture 10 - Convolutional Neural Networks, by Nando de Freitas, at Oxford University - Slides available at, https://www.cs.ox.ac.uk/people/nando.defreitas/ machinelearning/lecture9.pdf - Video available at, https://www.youtube.com/watch?v=bEUX_56Lojc"
  }
]